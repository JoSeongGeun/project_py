# wedding_recommender.py
import pandas as pd
import numpy as np
import json
from gensim.models.doc2vec import Doc2Vec, TaggedDocument
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity

# ===================== CSV ì €ì¥ í•¨ìˆ˜ =====================
def save_dataframe(df, filename="data.csv"):
    df_copy = df.copy()
    df_copy["tagged_doc"] = df_copy["tagged_doc"].apply(json.dumps)
    df_copy["doc2vec_vector"] = df_copy["doc2vec_vector"].apply(lambda x: json.dumps(x.tolist()) if isinstance(x, np.ndarray) else json.dumps(x))
    df_copy.to_csv(filename, index=False, encoding="utf-8-sig")
    print(f"âœ… DataFrameì´ '{filename}' íŒŒì¼ë¡œ ì €ì¥ë¨!")

# ===================== CSV ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜ =====================
def load_dataframe(filename="data.csv"):
    df = pd.read_csv(filename, encoding="utf-8-sig")
    df["tagged_doc"] = df["tagged_doc"].apply(json.loads)
    df["doc2vec_vector"] = df["doc2vec_vector"].apply(json.loads)
    df["doc2vec_vector"] = df["doc2vec_vector"].apply(lambda x: np.array(x))
    print(f"ğŸ“¥ '{filename}' íŒŒì¼ì—ì„œ DataFrame ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ!")
    return df

# ===================== ì¶”ì²œ í•¨ìˆ˜ =====================
def recommend_wedding_hall(survey_df, df, top_n=10, review_weight=1,
                           rental_fee_weight=0.7, food_price_weight=0.5,
                           mini_hc_weight=0.7, limit_hc_weight=0.1, car_park_weight=0.5):

    target_vector = survey_df.loc[0, "doc2vec_vector"].reshape(1, -1)
    all_vector = np.stack(df["doc2vec_vector"].values, axis=0)
    review_sim = cosine_similarity(target_vector, all_vector).flatten()

    target_rental_fee = survey_df.loc[0, "ëŒ€ê´€ë£Œ"]
    rental_fee_diff = np.abs(df["ëŒ€ê´€ë£Œ"].values.reshape(1, -1) - target_rental_fee)
    rental_fee_sim = 1 - MinMaxScaler().fit_transform(rental_fee_diff).flatten()

    target_food_price = survey_df.loc[0, "ì‹ëŒ€"]
    food_price_diff = np.abs(df["ì‹ëŒ€"].values.reshape(1, -1) - target_food_price)
    food_price_sim = 1 - MinMaxScaler().fit_transform(food_price_diff).flatten()

    target_mini_hc = survey_df.loc[0, "ìµœì†Œìˆ˜ìš©ì¸ì›"]
    all_mini_hc = df["ìµœì†Œìˆ˜ìš©ì¸ì›"].values
    valid_indices = np.where(all_mini_hc >= target_mini_hc)[0]

    df_filtered = df.iloc[valid_indices].reset_index(drop=True)
    review_sim = review_sim[valid_indices]
    rental_fee_sim = rental_fee_sim[valid_indices]
    food_price_sim = food_price_sim[valid_indices]
    all_mini_hc = all_mini_hc[valid_indices]

    mini_hc_diff = np.abs(all_mini_hc - target_mini_hc).reshape(-1, 1)
    mini_hc_sim = 1 - MinMaxScaler().fit_transform(mini_hc_diff).flatten()

    target_limit_hc = survey_df.loc[0, "ìµœëŒ€ìˆ˜ìš©ì¸ì›"]
    all_limit_hc = df_filtered["ìµœëŒ€ìˆ˜ìš©ì¸ì›"].values
    limit_hc_diff = np.abs(all_limit_hc - target_limit_hc)
    limit_hc_sim = 1 - MinMaxScaler().fit_transform(limit_hc_diff.reshape(-1, 1)).flatten()

    target_car_park = survey_df.loc[0, "ì£¼ì°¨ì¥(ëŒ€)"]
    all_car_park = df_filtered["ì£¼ì°¨ì¥(ëŒ€)"].values
    car_park_diff = np.abs(all_car_park - target_car_park)
    car_park_sim = 1 - MinMaxScaler().fit_transform(car_park_diff.reshape(-1, 1)).flatten()

    final_sim = (
        (review_sim * review_weight) +
        (rental_fee_sim * rental_fee_weight) +
        (food_price_sim * food_price_weight) +
        (mini_hc_sim * mini_hc_weight) +
        (limit_hc_sim * limit_hc_weight) +
        (car_park_sim * car_park_weight)
    )

    final_sim = (final_sim - final_sim.min()) / (final_sim.max() - final_sim.min())
    final_sim[0] = -np.inf

    selected_halls = []
    checked_names = set()

    for idx in np.argsort(final_sim)[::-1]:
        hall_name = df_filtered.loc[idx, "ì˜ˆì‹ì¥"]
        if hall_name not in checked_names:
            selected_halls.append(idx)
            checked_names.add(hall_name)
        if len(selected_halls) == top_n:
            break

    top_indices = selected_halls

    target_df = survey_df.loc[[0], ["ëŒ€ê´€ë£Œ", "ì‹ëŒ€", "ìµœì†Œìˆ˜ìš©ì¸ì›", "ìµœëŒ€ìˆ˜ìš©ì¸ì›", "ì£¼ì°¨ì¥(ëŒ€)"]].copy()
    result_df = df_filtered.loc[top_indices, ["ì˜ˆì‹ì¥", "ëŒ€ê´€ë£Œ", "ì‹ëŒ€", "ìµœì†Œìˆ˜ìš©ì¸ì›", "ìµœëŒ€ìˆ˜ìš©ì¸ì›", "ì£¼ì°¨ì¥(ëŒ€)"]].copy()
    result_df["final_similarity"] = final_sim[top_indices]

    return target_df, result_df

# ===================== ì‹¤í–‰ë¶€ =====================
if __name__ == "__main__":
    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    df = load_dataframe()

    # ì„¤ë¬¸ ë°ì´í„° ì˜ˆì‹œ
    survey = {
        "ë¦¬ë·°": [['ì¢‹ë‹¤', 'ë©‹ì§€ë‹¤', 'ì˜ˆì˜ë‹¤', 'ì¶•ë³µ', 'ê´‘ì£¼', 'ê²°í˜¼ì‹']],
        "ëŒ€ê´€ë£Œ": [2000000],
        "ì‹ëŒ€": [60000],
        "ìµœì†Œìˆ˜ìš©ì¸ì›": [150],
        "ìµœëŒ€ìˆ˜ìš©ì¸ì›": [1000],
        "ì£¼ì°¨ì¥(ëŒ€)": [1000]
    }
    survey_df = pd.DataFrame(survey)

    # Doc2Vec ëª¨ë¸ í•™ìŠµ
    documents = [TaggedDocument(words=review, tags=[i]) for i, review in enumerate(survey_df["ë¦¬ë·°"])]
    model = Doc2Vec(vector_size=300, window=5, min_count=1, workers=4, epochs=20)
    model.build_vocab(documents)
    model.train(documents, total_examples=model.corpus_count, epochs=model.epochs)
    survey_df["doc2vec_vector"] = survey_df["ë¦¬ë·°"].apply(lambda x: model.infer_vector(x))

    # ì¶”ì²œ í•¨ìˆ˜ í˜¸ì¶œ
    target_info, recommendation = recommend_wedding_hall(
        survey_df, df,
        top_n=5,
        review_weight=1,
        rental_fee_weight=0.7,
        food_price_weight=0.5,
        mini_hc_weight=0.7,
        limit_hc_weight=0.1,
        car_park_weight=0.5
    )

    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ¯ ì‚¬ìš©ì ì…ë ¥ ê¸°ì¤€ ì •ë³´:")
    print(target_info.to_string(index=False))

    print("\nğŸ† ì¶”ì²œ ì˜ˆì‹ì¥ ë¦¬ìŠ¤íŠ¸:")
    print(recommendation.to_string(index=False))


